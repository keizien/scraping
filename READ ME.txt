Projet : Compta Fiscal â€“ Articles Scraper
Scraper Python permettant dâ€™extraire lâ€™ensemble des articles du site
https://compta.webwin.be
afin de les rÃ©importer automatiquement dans WordPress.

ğŸ¯ Objectif du projet
RÃ©cupÃ©rer tous les articles du site (â‰ˆ 1300+)
Extraire :
- Titre
- URL
- Date de publication
- Contenu HTML
- GÃ©nÃ©rer un CSV exploitable
- Permettre une reprise automatique en cas dâ€™arrÃªt
- Ã‰viter tout blocage serveur (scraping â€œsafeâ€)

âš™ï¸ FonctionnalitÃ©s
- Extraction complÃ¨te des articles (toutes catÃ©gories confondues)
- Scraping page par page via URLs rÃ©elles (pas de JS fragile)
- Scraping du contenu article par article
- Sauvegarde progressive (reprise possible)
- Pauses alÃ©atoires pour simuler un comportement humain
- Export CSV compatible import WordPress
- Logs clairs (progression, erreurs, reprise)


Choix techniques (important pour le jury / tuteur)
Pourquoi pas Selenium ?
- Trop lent
- Trop instable
- Surconsommation de ressources
- Inutile une fois les URLs connues


Selenium a servi uniquement Ã  comprendre la structure du site.
Stack finale
- requests â†’ requÃªtes HTTP
- BeautifulSoup â†’ parsing HTML
- pandas â†’ CSV final
- time / random â†’ anti-blocage
- Scraping sÃ©quentiel volontairement lent


PrÃ©requis
- Python 3.9+
- Pip


Installation
git clone <repo>
cd scrap-compta-fiscal
python -m venv .venv


Activation de lâ€™environnement
Windows (PowerShell)
.venv\Scripts\Activate.ps1

Windows (CMD)
.venv\Scripts\activate.bat

Linux / macOS
source .venv/bin/activate

DÃ©pendances
pip install -r requirements.txt

Utilisation
Ã‰tape 1 â€“ RÃ©cupÃ©ration de toutes les URLs
python selenium_test.py

GÃ©nÃ¨re :
tous_les_articles.csv

Colonnes :
- titre
- url


Ã‰tape 2 â€“ Scraping du contenu des articles
python scrape_content.py

Fonctionnement :
- Lit tous_les_articles.csv
- Ignore automatiquement les articles dÃ©jÃ  traitÃ©s
- Peut Ãªtre arrÃªtÃ© / relancÃ© sans perte
- Sauvegarde progressive


Structure du projet
scrap-compta-fiscal/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tous_les_articles.csv
â”‚   â”œâ”€â”€ articles_complets.csv
â”‚
â”œâ”€â”€ scrape_list.py
â”œâ”€â”€ scrape_content.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .venv/


RÃ©sultats
- 1375 articles rÃ©cupÃ©rÃ©s
- Temps total :
- Liste : quelques minutes
- Contenu : plus long (scraping sÃ©curisÃ©)
- Taux dâ€™erreur : trÃ¨s faible
- Aucun blocage serveur constatÃ©


Import dans WordPress

MÃ©thodes possibles :
RecommandÃ©e
- WP All Import
- Mapping :
	Titre â†’ post_title
	Contenu HTML â†’ post_content
	Date â†’ post_date
	CatÃ©gories â†’ taxonomies

Alternatives
- WordPress REST API
- WP-CLI


Limitations connues
- Scraping volontairement lent (anti-bot)
- Pas de multi-threading agressif
- DÃ©pendant de la structure HTML actuelle du site


Conclusion
- Ce projet met en Å“uvre :
- une vraie mÃ©thodologie de scraping
- une approche robuste et responsable
- une sÃ©paration claire des Ã©tapes
- une solution directement exploitable en production WordPress